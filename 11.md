爬虫开发的基础知识

#### 1.1、爬虫是什么？
	
爬虫（网络爬虫），是一种运行在互联网上用来获取数据的自动化程序或者脚本。
* 互联网：各种形形色色的网站
	* 新闻网站，网易，搜狐，今日头条……
	* 视频网站，优酷，爱奇艺
	* ……
* **获取数据**：不同类型，不同行业网站上的数据
* 自动化：通过程序实现自动化，尽可能减少人工干预。

#### 1.2、爬虫抓取的数据有什么用？
* 帮助用户从海量数据中快捷获取到有用的信息
* 获取微博，QQ，微信中的数据，做数据分析
	* 用户社交圈：关注了谁，谁是你的好友的好友
	* 用户的喜好：你关注、评论的话题、文章
	* ……
* 获取政府公开数据
	* 公司注册信息
	* 法院信息收集，标记违法人或者公司
	* ……
* 获取行业的信息
	* 互联网电商：淘宝，京东，苏宁，国美
		* 小米手机的价格，销量，评价
	* 行业领头羊公司经营分析

通过不同渠道和手段爬取需要的数据，解决某一个类特定的问题。

#### 1.3、爬虫的简单分类
* 垂直爬虫
	* 只爬取一类信息
		* 垂直爬虫A：只爬取公司注册信息
		* 垂直爬虫B：只爬取法院的信息
* 通用爬虫
	* 爬取互联网上所有出现网站的信息
		* 百度
		* 谷歌
爬虫的分类有很多，我们一般爬虫爬取的数据范围进行分类，如果只爬取一类数据我们叫做垂直爬虫，如果是爬取互联网上所有的网站数据，我们叫做通用爬虫。

#### 1.4、爬虫的基本运行原理

普通用户获取新浪网站上的数据的操作记录

* 打开浏览器
* 输入一个网址：www.sina.com
* 新浪服务器返回一个HTML文档
	* 获取HTML文档里面新闻链接
		* 从所有的连接里面选择一个
* 点击链接，通过浏览器发送HTTP请求
* 新闻对应的服务器返回一个HTML文档
	* 新闻内容：标题，内容，作者，发布时间，点赞
	* 解析除了新闻内容之外的相关信息的连接
		* ？保存起来
* 保存新闻的内容

爬虫的步骤
* 给定一个URL:WWW.SINA.COM
* 模拟浏览器发送一个HTTP请求，得到一个HTML文档
* 爬虫 解析 HTML文档
	* 使用Document获取HTML文档
		* 解析新闻正文
		* 解析出所有的新闻链接
	* 将新闻的正文保存起来
	* 将所有的新闻链接保存起来
* 从保存新闻链接的地方，在获取一个新的URL
	* 模拟浏览器发送一个HTTP请求，得到一个HTML文档
	* 爬虫 解析 HTML文档
		* 使用Document获取HTML文档
			* 解析新闻正文
			* 解析出所有的新闻链接
		* 将新闻的正文保存起来
		* 将所有的新闻链接保存起来 
* 依次循环

#### 1.5、爬虫开发的技术问题
* 如何模拟浏览器发送一个HTTP请求？
	* 模拟发送请求
	* HTTP协议
* 如何解析HTML文档？
	* 回顾HTML文档
	* 如何快速解析Document获得想要数据？
* 解析出来的数据保存到哪里？
	* 新闻正文保存到哪里？
		* 保存到数据库/文本文件
		* 特点：解析出来之后，不再修改，可以固定保存
	* 所有新的URL保存到哪里？
		* 读取URL需要一个顺序（先进先出）
			* 队列 Queue
* 如果等待爬取的URL中有重复URL时，是不是要多次爬取？
	* 如何避免重复爬取？
		* 标记已经爬取过的数据？
		* 标记爬取
			* 在爬取之前，先去一个地方查询改URL是否爬取过
			* 如果没有爬取，就发去HTTP请求，爬取URL
				* 爬取成功之后，就将URL放入已经爬取的队列中。
			* 如果已经爬取过，就不爬取
		* SET处理，非空去重。
* 单个线程爬取页面信息，比较慢而URL又特别多？
	* 多线程